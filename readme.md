# Titanic Dataset Analysis

## üìã –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞
–ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ Titanic —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–µ—Ç–æ–¥–æ–≤ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è. –ó–∞–¥–∞—á–∞ –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ - –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –≤—ã–∂–∏–≤–∞–µ–º–æ—Å—Ç—å –ø–∞—Å—Å–∞–∂–∏—Ä–æ–≤.

## üéØ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞

### –ú–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª–µ–π:
- **K-NN (k=9)**: Accuracy = 73.33% (–ª—É—á—à–∞—è –º–æ–¥–µ–ª—å)
- **Random Forest**: Accuracy = 60.00%
- **Logistic Regression**: Accuracy = 53.33%
- **Decision Tree**: Accuracy = 53.33%

### –ö–ª—é—á–µ–≤—ã–µ –≤—ã–≤–æ–¥—ã:
1. **–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å**: K-Nearest Neighbors —Å k=9
2. **–¢–æ—á–Ω–æ—Å—Ç—å**: 73.33% –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ
3. **–í–∞–∂–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏**: –í–æ–∑—Ä–∞—Å—Ç, —Å—Ç–æ–∏–º–æ—Å—Ç—å –±–∏–ª–µ—Ç–∞, –ø–æ—Ä—Ç –ø–æ—Å–∞–¥–∫–∏
4. **–ö–∞—á–µ—Å—Ç–≤–æ**: F1-score = 81.82% (—Ö–æ—Ä–æ—à–∏–π –±–∞–ª–∞–Ω—Å precision/recall)

## üõ† –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏
- Python 3.8+
- pandas, numpy
- scikit-learn
- matplotlib, seaborn

## üöÄ –ó–∞–ø—É—Å–∫ –ø—Ä–æ–µ–∫—Ç–∞
```bash
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
pip install -r requirements.txt

# –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
python create_full_sample.py

# –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞
python titanic_analysis_perfect.py